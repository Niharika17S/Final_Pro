{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import wordcloud\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hello\\Desktop\\Anaconda\\envs\\PythonData\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer,TfidfTransformer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "# from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DOC_ID</th>\n",
       "      <th>LABEL</th>\n",
       "      <th>RATING</th>\n",
       "      <th>VERIFIED_PURCHASE</th>\n",
       "      <th>PRODUCT_CATEGORY</th>\n",
       "      <th>PRODUCT_ID</th>\n",
       "      <th>PRODUCT_TITLE</th>\n",
       "      <th>REVIEW_TITLE</th>\n",
       "      <th>REVIEW_TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>__label1__</td>\n",
       "      <td>4</td>\n",
       "      <td>Y</td>\n",
       "      <td>Health &amp; Personal Care</td>\n",
       "      <td>B00KNXIDH6</td>\n",
       "      <td>100 Tablet CleanGuard Nightguard Cleaner</td>\n",
       "      <td>and he was satisfied with this</td>\n",
       "      <td>These tablets are especially helpful if you us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>__label1__</td>\n",
       "      <td>4</td>\n",
       "      <td>N</td>\n",
       "      <td>Home</td>\n",
       "      <td>B00LWRZFAA</td>\n",
       "      <td>Birds Flying Black Tree Branches Wall Sticker ...</td>\n",
       "      <td>best of money value</td>\n",
       "      <td>Looking decent as same shown in photos Thank Y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>__label1__</td>\n",
       "      <td>4</td>\n",
       "      <td>Y</td>\n",
       "      <td>Health &amp; Personal Care</td>\n",
       "      <td>B00B2YGB9M</td>\n",
       "      <td>Garcinia Cambogia Pure Extract Supplement, 80%...</td>\n",
       "      <td>It's harder to lose weight the older you get</td>\n",
       "      <td>I find that the older I get, the harder it is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23</td>\n",
       "      <td>__label1__</td>\n",
       "      <td>3</td>\n",
       "      <td>N</td>\n",
       "      <td>Camera</td>\n",
       "      <td>B004TJ6JH6</td>\n",
       "      <td>NEEWER® 160 LED CN-160 Dimmable Ultra High Pow...</td>\n",
       "      <td>So easy to use!!</td>\n",
       "      <td>I have had my camera for about 2 weeks now. Th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24</td>\n",
       "      <td>__label1__</td>\n",
       "      <td>2</td>\n",
       "      <td>Y</td>\n",
       "      <td>Health &amp; Personal Care</td>\n",
       "      <td>B00OBDRLVS</td>\n",
       "      <td>NatureWise Garcinia Cambogia Extract (Not Synt...</td>\n",
       "      <td>Stay Away And Don't Buy It</td>\n",
       "      <td>It is highly recommended not to buy this produ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DOC_ID       LABEL  RATING VERIFIED_PURCHASE        PRODUCT_CATEGORY  \\\n",
       "0      20  __label1__       4                 Y  Health & Personal Care   \n",
       "1      21  __label1__       4                 N                    Home   \n",
       "2      22  __label1__       4                 Y  Health & Personal Care   \n",
       "3      23  __label1__       3                 N                  Camera   \n",
       "4      24  __label1__       2                 Y  Health & Personal Care   \n",
       "\n",
       "   PRODUCT_ID                                      PRODUCT_TITLE  \\\n",
       "0  B00KNXIDH6           100 Tablet CleanGuard Nightguard Cleaner   \n",
       "1  B00LWRZFAA  Birds Flying Black Tree Branches Wall Sticker ...   \n",
       "2  B00B2YGB9M  Garcinia Cambogia Pure Extract Supplement, 80%...   \n",
       "3  B004TJ6JH6  NEEWER® 160 LED CN-160 Dimmable Ultra High Pow...   \n",
       "4  B00OBDRLVS  NatureWise Garcinia Cambogia Extract (Not Synt...   \n",
       "\n",
       "                                   REVIEW_TITLE  \\\n",
       "0                and he was satisfied with this   \n",
       "1                           best of money value   \n",
       "2  It's harder to lose weight the older you get   \n",
       "3                              So easy to use!!   \n",
       "4                    Stay Away And Don't Buy It   \n",
       "\n",
       "                                         REVIEW_TEXT  \n",
       "0  These tablets are especially helpful if you us...  \n",
       "1  Looking decent as same shown in photos Thank Y...  \n",
       "2  I find that the older I get, the harder it is ...  \n",
       "3  I have had my camera for about 2 weeks now. Th...  \n",
       "4  It is highly recommended not to buy this produ...  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1_review = pd.read_csv('C:/Users/hello/Desktop/Project3/resources/amazon_reviews_v2.csv',low_memory=False)\n",
    "df1_review.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Insert pos_neg column for Sentiment modeling\n",
    "     Negative reviews:      1-3 Stars  = 0\n",
    "     Positive reviews:      4-5 Stars  = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_review['pos_neg'] = [1 if x > 3 else 0 for x in df1_review.RATING]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pos_neg</th>\n",
       "      <th>REVIEW_TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>These tablets are especially helpful if you us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Looking decent as same shown in photos Thank Y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>I find that the older I get, the harder it is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>I have had my camera for about 2 weeks now. Th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>It is highly recommended not to buy this produ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pos_neg                                        REVIEW_TEXT\n",
       "0        1  These tablets are especially helpful if you us...\n",
       "1        1  Looking decent as same shown in photos Thank Y...\n",
       "2        1  I find that the older I get, the harder it is ...\n",
       "3        0  I have had my camera for about 2 weeks now. Th...\n",
       "4        0  It is highly recommended not to buy this produ..."
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_review = df1_review[['pos_neg','REVIEW_TEXT']].copy()\n",
    "df_review.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     These tablets are especially helpful if you us...\n",
       "1     Looking decent as same shown in photos Thank Y...\n",
       "2     I find that the older I get, the harder it is ...\n",
       "3     I have had my camera for about 2 weeks now. Th...\n",
       "4     It is highly recommended not to buy this produ...\n",
       "5     The actual power supply is good, but the cable...\n",
       "6     My personal physician recommended it and I bou...\n",
       "7     I love the fact that you can easily read the m...\n",
       "8     I have bought several products from this selle...\n",
       "9     This is an extremely well made electric blanke...\n",
       "10    great product for coffee lover that want littl...\n",
       "11    I figured it would for sure fit a dasani bottl...\n",
       "12    This dinnerware set provides a very nice aesth...\n",
       "13    The sides of the case didn't match my phone at...\n",
       "14    Since I have a low pain tolerance this facial ...\n",
       "15    The bag looks like a little smaller version th...\n",
       "16    Bought this to use with my gel eyeliner. The h...\n",
       "17    This mask is great for the purpose of keeping ...\n",
       "18    I used this in my photoshoot last month.. It's...\n",
       "Name: REVIEW_TEXT, dtype: object"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replace NaN values with some value of their own.\n",
    "df_review.REVIEW_TEXT.fillna(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['These tablets are especially helpful if you use the Secure dental adhesive.<br />I bought this stuff for my father. and he was satisfied with this.',\n",
       "       'Looking decent as same shown in photos Thank You amazon .I saved cost as paint of this type is very costly and as this is digitally print looking decent.',\n",
       "       \"I find that the older I get, the harder it is to lose weight....but I've gotten great results taking garcinia this month. I take it before breakfast, lunch and supper. I don't take the one after supper because I don't tend to eat much in the late evenings. I find it really cuts my down my appetite. I've lost 8 lbs this month, which is WAY more than I've lost in a long time.\",\n",
       "       'I have had my camera for about 2 weeks now. The pictures are great, it is so easy to use. I love it!!',\n",
       "       'It is highly recommended not to buy this product.  I took the suggested dosage for a week and felt nothing, no extra energy, no loss of appetite, no pounds lost.',\n",
       "       \"The actual power supply is good, but the cable harness's had to be completely taken apart and re-oriented to avoid a birds nest of backwards wiring in tower. It's like they didn't test it to see if it works.\",\n",
       "       \"My personal physician recommended it and I bought at goo.gl/wa7AI ,with $10 off and free samples. Great stuff!!!!!<br /><br />I was told the enormous benifit of Oregano: it is one of the most powerful healing herbs and natural anti-biotics ever studied. It has been found in a recent study to be significantly better than all of the 18 currently used anti-biotics in the treatment of MRSA staph infections. The strong phenol anti-oxidants destroy pathogenic bacteria, viruses and yeasts. This super herb is very rich in anti-oxidant phytochemical flavonoids and phenolic acids. It is the third highest herb in oxygen radical absorbancy capacity (ORAC) with an impressive score of 200,129. The USDA ranks oregano's antioxidant capacity anywhere from 3 to 20 times higher than any other herb.<br /><br />You can see 2 bottles Oreganol P73 in my fridge. Wowww ... this oregano oil is just the best, it works miraculously! I had discomfort and dryness in my throat, then I took a couple drops of this oil in a tablespoon of water and drank it. This oil healed and soothed my throat almost instantly, and feel great up to now. Another time I felt my body so aching, then I took this oil in the same way - it set me free and felt great just in seconds. This oil is fantastic!!! I also have used oregano as emergency medicine to completely eliminate digestive distress after eating what I found out was contaminated food.\",\n",
       "       \"I love the fact that you can easily read the measurements...great for those of us who's eyes aren't what they use to be LOL. I get so tired of trying to read the numbers on those others where it's the same color as the cup itself.\",\n",
       "       'I have bought several products from this seller and I have been pleased with all of them. The green coffee does exactly what it says it does! I am happy with it and will purchase another once I am finished with this bottle.',\n",
       "       'This is an extremely well made electric blanket. We tried 2 before this one & took both back. You cannot feel the wires and the material is very luxurious. I did feel it was quite pricey...about $50 more than the ones we took back. However, that being said, the quality indicates it will last for years.',\n",
       "       'great product for coffee lover that want little more rich flavor on their coffee. Love that is easy to clean.',\n",
       "       \"I figured it would for sure fit a dasani bottle.... it doesn't.  I have been able to use it with cheap water bottles though.\",\n",
       "       'This dinnerware set provides a very nice aesthetic. It will allow you to set your table very decoratively, and the beauty of a white dinnerware set is that it goes with any color scheme! Before acquiring this particular dinnerware set, I already owned a plain white set of dinnerware; but this set with the platinum rim is much nicer.',\n",
       "       \"The sides of the case didn't match my phone at all but the real issue is when the tan color became blackish in some parts. Looks unpleasant and can't use like that.\",\n",
       "       \"Since I have a low pain tolerance this facial hair remover didn't hurt very much. It did take a lot of hair off my face which I love because I hate peach fuzz, especially when wearing foundation. The tweezers were okay, loved the color but it was a little hard for me to use. Wish the package was bubble wrapped because it was so cute but mine got smashed in the process of shipping. Great customer service!!\",\n",
       "       'The bag looks like a little smaller version than the one in the picture. The picture shows a lot and describes how much it holds. I found it hard to accommodate my D3100 and two lenses along with the battery charger.',\n",
       "       'Bought this to use with my gel eyeliner. The handle is longer than I liked but it works well. I like that it is slanted and very easy to apply and clean.',\n",
       "       'This mask is great for the purpose of keeping out the light for sure! My hubs gets up at 4am to go work and he is a butthead by turning on all the lights. Since getting this, Ive havent had any issues sleeping through it! lol. It looks like a mini bra because its not like your traditional flat sleep masks that lay flat over your eyes. This one has little &#34;cups&#34; that doesnt touch your eyelids at all which is nice because with my old sleep mask it made me itchy. The only reason why I didnt give this 5 stars is because whenever I turned to sleep on my sides it kinda made it uncomfortable to sleep with it on. I had to sleep on my back to make it stay on. For me I hate sleeping on my back so :(',\n",
       "       \"I used this in my photoshoot last month.. It's really cool.. it has a nice built quality and vintage look.. really awesome..\"],\n",
       "      dtype='<U1414')"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_review['REVIEW_TEXT'].values.astype('U')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_review['REVIEW_TEXT'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    13\n",
       "0     6\n",
       "Name: pos_neg, dtype: int64"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_review['pos_neg'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19 entries, 0 to 18\n",
      "Data columns (total 2 columns):\n",
      "pos_neg        19 non-null int64\n",
      "REVIEW_TEXT    19 non-null object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 384.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "df_review.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [When, least, you, think, so, this, product, w...\n",
       "1    [Lithium, batteries, are, something, new, intr...\n",
       "2    [I, purchased, this, swing, for, my, baby, She...\n",
       "3    [I, was, looking, for, an, inexpensive, desk, ...\n",
       "4    [I, only, use, it, twice, a, week, and, the, r...\n",
       "Name: REVIEW_TEXT, dtype: object"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TextBlob(message).words will give us collection of words from a sentence.\n",
    "def split_into_tokens(sentence):\n",
    "    return TextBlob(sentence).words\n",
    "\n",
    "df_review.REVIEW_TEXT.head().apply(split_into_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [when, least, you, think, so, this, product, w...\n",
       "1    [lithium, battery, are, something, new, introd...\n",
       "2    [i, purchased, this, swing, for, my, baby, she...\n",
       "3    [i, wa, looking, for, an, inexpensive, desk, c...\n",
       "4    [i, only, use, it, twice, a, week, and, the, r...\n",
       "Name: REVIEW_TEXT, dtype: object"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lemma is converting words into it's root form. \n",
    "def split_into_lemmas(message):\n",
    "    message = message.lower()\n",
    "    words = TextBlob(message).words\n",
    "    return [word.lemma for word in words]\n",
    "\n",
    "df_review.REVIEW_TEXT.head().apply(split_into_lemmas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification/Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewcloud = wordcloud.WordCloud(background_color='pink', max_font_size=50, \n",
    "                                relative_scaling=1).generate(' '.join(str(n)for n in df_review.REVIEW_TEXT))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 10))\n",
    "plt.axis('off')\n",
    "plt.imshow(reviewcloud);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/Split\n",
    "#train for the models on the data given. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_review.REVIEW_TEXT, df_review.pos_neg,test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (15,)\n",
      "y_train shape: (15,)\n",
      "\n",
      "X_test shape: (4,)\n",
      "y_test shape: (4,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train shape: {}\".format(X_train.shape), end='\\n')\n",
    "print(\"y_train shape: {}\".format(y_train.shape), end='\\n\\n')\n",
    "print(\"X_test shape: {}\".format(X_test.shape), end='\\n')\n",
    "print(\"y_test shape: {}\".format(y_test.shape), end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test = pd.Series(X_test.flatten())\n",
    "# X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CountVectorization\n",
    "#list of tokens (lemmas) above is converted into a vector that machine learning models can understand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_vect:\n",
      "<15x410 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 689 stored elements in Compressed Sparse Row format>\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(analyzer=split_into_lemmas, ngram_range=(2,4),\n",
    "    lowercase = False,)\n",
    "X_train_vect = vectorizer.fit_transform((X_train).values.astype(str))\n",
    "print(\"X_train_vect:\\n{}\".format(repr(X_train_vect)))\n",
    "\n",
    "#Pandas astype()methods is used to change data type of a series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "410\n"
     ]
    }
   ],
   "source": [
    "#vectorizer.vocabulary_\n",
    "print( len(vectorizer.vocabulary_))\n",
    "\n",
    "#Each vector has as many dimensions as there are unique words in the corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 1, ..., 1, 1, 0]], dtype=int64)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_vect.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 410\n"
     ]
    }
   ],
   "source": [
    "feature_names = vectorizer.get_feature_names()\n",
    "print(\"Number of features: {}\".format(len(feature_names)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<15x410 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 689 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# giving less weightage to frequently occuring words,\n",
    "# the term weighting and normalization is done with TF-IDF, using scikit-learn's TfidfTransformer:\n",
    "transformer = TfidfTransformer(smooth_idf=False)\n",
    "tfidf_X_train = transformer.fit_transform(X_train_vect)\n",
    "\n",
    "tfidf_X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15, 410)\n"
     ]
    }
   ],
   "source": [
    "# tfidf_X_train.toarray()\n",
    "print(tfidf_X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tfidf_X_train.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting in the model - logistic Regression\n",
    "logreg = LogisticRegression(C=0.1).fit(tfidf_X_train, y_train)\n",
    "logreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_vect = vectorizer.transform((X_test).values.astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_X_test = transformer.transform(X_test_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('lg', LogisticRegression()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(X_train, y_train)\n",
    "pipeline.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 86 features per sample; expecting 410",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-126-5599eef7f8e2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Now, the model logreg is ready to predict on the test data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mlog_y_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogreg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtfidf_X_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Desktop\\Anaconda\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\base.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    322\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mper\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m         \"\"\"\n\u001b[1;32m--> 324\u001b[1;33m         \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    325\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Anaconda\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    303\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mn_features\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m             raise ValueError(\"X has %d features per sample; expecting %d\"\n\u001b[1;32m--> 305\u001b[1;33m                              % (X.shape[1], n_features))\n\u001b[0m\u001b[0;32m    306\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    307\u001b[0m         scores = safe_sparse_dot(X, self.coef_.T,\n",
      "\u001b[1;31mValueError\u001b[0m: X has 86 features per sample; expecting 410"
     ]
    }
   ],
   "source": [
    "#Now, the model logreg is ready to predict on the test data.\n",
    "log_y_pred = logreg.predict(tfidf_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_score = accuracy_score(y_test, log_y_pred)\n",
    "print(\"Accuracy:   {:.3f}\".format(logreg_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_cfm = confusion_matrix(y_test, log_y_pred)\n",
    "print(\"Confusion matrix:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_f1 = f1_score(y_test, log_y_pred)\n",
    "print(\"Logistic Reg - F1 score: {:.3f}\".format(log_f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis\n",
    "The sentiment property returns a namedtuple of the form Sentiment(polarity, subjectivity). The polarity score is a float within the range [-1.0, 1.0]. \n",
    "The subjectivity is a float within the range [0.0, 1.0] where 0.0 is very objective and 1.0 is very subjective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_review.to_csv(\"reviewtext.csv\", sep=\",\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment(classification='pos', p_pos=0.5, p_neg=0.5)\n",
      "Sentiment(classification='pos', p_pos=0.5, p_neg=0.5)\n",
      "Sentiment(classification='pos', p_pos=0.5, p_neg=0.5)\n",
      "Sentiment(classification='pos', p_pos=0.5, p_neg=0.5)\n",
      "Sentiment(classification='pos', p_pos=0.5, p_neg=0.5)\n",
      "Sentiment(classification='pos', p_pos=0.5, p_neg=0.5)\n",
      "Sentiment(classification='pos', p_pos=0.5, p_neg=0.5)\n",
      "Sentiment(classification='pos', p_pos=0.5, p_neg=0.5)\n",
      "Sentiment(classification='pos', p_pos=0.5, p_neg=0.5)\n",
      "Sentiment(classification='pos', p_pos=0.5, p_neg=0.5)\n",
      "Sentiment(classification='pos', p_pos=0.5, p_neg=0.5)\n",
      "Sentiment(classification='pos', p_pos=0.5, p_neg=0.5)\n",
      "Sentiment(classification='pos', p_pos=0.5, p_neg=0.5)\n",
      "Sentiment(classification='pos', p_pos=0.5, p_neg=0.5)\n",
      "Sentiment(classification='pos', p_pos=0.5, p_neg=0.5)\n",
      "Sentiment(classification='pos', p_pos=0.5, p_neg=0.5)\n",
      "Sentiment(classification='pos', p_pos=0.5, p_neg=0.5)\n",
      "Sentiment(classification='pos', p_pos=0.5, p_neg=0.5)\n",
      "Sentiment(classification='pos', p_pos=0.5, p_neg=0.5)\n",
      "Sentiment(classification='pos', p_pos=0.5, p_neg=0.5)\n"
     ]
    }
   ],
   "source": [
    "infile = \"reviewtext.csv\"\n",
    "from textblob.sentiments import NaiveBayesAnalyzer\n",
    "n_list = list()\n",
    "p_list = list()\n",
    "c_list = list()\n",
    "with open(infile, 'r') as csvfile:\n",
    "    rows = csv.reader(csvfile)\n",
    "    for row in rows:\n",
    "        sentence = row[0]\n",
    "        blob = TextBlob(sentence,analyzer=NaiveBayesAnalyzer() )\n",
    "        each_sentiment = blob.sentiment\n",
    "#         n_list.append(each_sentiment.p_neg)\n",
    "#         p_list.append(each_sentiment.p_pos)\n",
    "#         c_list.append(each_sentiment.classification)\n",
    "#         d = dict()\n",
    "#         d['classification']=c_list\n",
    "#         d['p_pos']=p_list\n",
    "#         d['p_neg']=n_list\n",
    "        print(each_sentiment)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classification</th>\n",
       "      <th>p_pos</th>\n",
       "      <th>p_neg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pos</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pos</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pos</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pos</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pos</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pos</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>pos</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>pos</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>pos</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>pos</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>pos</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>pos</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>pos</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>pos</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>pos</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>pos</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>pos</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>pos</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>pos</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>pos</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   classification  p_pos  p_neg\n",
       "0             pos    0.5    0.5\n",
       "1             pos    0.5    0.5\n",
       "2             pos    0.5    0.5\n",
       "3             pos    0.5    0.5\n",
       "4             pos    0.5    0.5\n",
       "5             pos    0.5    0.5\n",
       "6             pos    0.5    0.5\n",
       "7             pos    0.5    0.5\n",
       "8             pos    0.5    0.5\n",
       "9             pos    0.5    0.5\n",
       "10            pos    0.5    0.5\n",
       "11            pos    0.5    0.5\n",
       "12            pos    0.5    0.5\n",
       "13            pos    0.5    0.5\n",
       "14            pos    0.5    0.5\n",
       "15            pos    0.5    0.5\n",
       "16            pos    0.5    0.5\n",
       "17            pos    0.5    0.5\n",
       "18            pos    0.5    0.5\n",
       "19            pos    0.5    0.5"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = pd.DataFrame(d)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 100.0% via 21 samples\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "count = 0\n",
    "with open(infile, encoding=\"utf8\",mode = 'r') as file:\n",
    "    for line in file.read().split('\\n'):\n",
    "            analysis = TextBlob(line)\n",
    "            if analysis.sentiment.polarity <=0.7:\n",
    "                correct +=1\n",
    "            count +=1    \n",
    "print(\"Accuracy = {}% via {} samples\".format(correct/count*100,count))     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob.sentiments import NaiveBayesAnalyzer\n",
    "\n",
    "\n",
    ">>> blob = TextBlob(\"I love this library\", analyzer=NaiveBayesAnalyzer())\n",
    ">>> blob.sentiment"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
